{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import nltk\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
       " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
       " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n",
       " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n",
       " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_ids = {}\n",
    "for line in lines:\n",
    "    line_lst = line.split(' +++$+++ ')\n",
    "    if len(line_lst) == 5:\n",
    "        line_ids[line_lst[0]] = line_lst[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = []\n",
    "for line in conv:\n",
    "    line_lst = line.split(' +++$+++ ')\n",
    "    line = line_lst[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
    "    convs.append(line.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate question and answers \n",
    "questions = []\n",
    "answers = []\n",
    "for conv in convs:\n",
    "    if len(conv) %2 != 0:\n",
    "        conv = conv[:-1]    \n",
    "    for i in range(len(conv)):\n",
    "        if i%2 == 0:\n",
    "            questions.append(line_ids[conv[i]])\n",
    "        else:\n",
    "            answers.append(line_ids[conv[i]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to lowercase\n",
    "questions = [ line.lower() for line in questions ]\n",
    "answers = [ line.lower() for line in answers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can we make this quick?  roxanne korrine and andrew barrett are having an incredibly horrendous public break- up on the quad.  again.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"well, i thought we'd start with pronunciation, if that's okay with you.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters \n",
    "EN_WHITELIST = '0123456789abcdefghijklmnopqrstuvwxyz ' # space is included in whitelist\n",
    "EN_BLACKLIST = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\''\n",
    "def filter_line(line, whitelist):\n",
    "    return ''.join([ ch for ch in line if ch in whitelist ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [ filter_line(line, EN_WHITELIST) for line in questions ]\n",
    "answers = [ filter_line(line, EN_WHITELIST) for line in answers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can we make this quick  roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad  again'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well i thought wed start with pronunciation if thats okay with you'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(qseq, aseq):\n",
    "    filtered_q, filtered_a = [], []\n",
    "    raw_data_len = len(qseq)\n",
    "    for i in range(raw_data_len):\n",
    "        qlen, alen = len(qseq[i].split(' ')), len(aseq[i].split(' '))\n",
    "        if qlen >= 2 and qlen <= 25:\n",
    "            if alen >= 2 and alen <= 25:\n",
    "                filtered_q.append(qseq[i])\n",
    "                filtered_a.append(aseq[i])\n",
    "\n",
    "    return filtered_q, filtered_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = filter_data(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "question_tokens = [ [w.strip() for w in wordlist.split(' ') if w] for wordlist in questions ]\n",
    "answer_tokens   = [ [w.strip() for w in wordlist.split(' ') if w] for wordlist in answers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can',\n",
       " 'we',\n",
       " 'make',\n",
       " 'this',\n",
       " 'quick',\n",
       " 'roxanne',\n",
       " 'korrine',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'barrett',\n",
       " 'are',\n",
       " 'having',\n",
       " 'an',\n",
       " 'incredibly',\n",
       " 'horrendous',\n",
       " 'public',\n",
       " 'break',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'quad',\n",
       " 'again']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'wed',\n",
       " 'start',\n",
       " 'with',\n",
       " 'pronunciation',\n",
       " 'if',\n",
       " 'thats',\n",
       " 'okay',\n",
       " 'with',\n",
       " 'you']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization: Words to index and index to words\n",
    "UNK = 'unk'\n",
    "freq_dist = nltk.FreqDist(itertools.chain(*(question_tokens + answer_tokens)))\n",
    "vocab = freq_dist.most_common(8000)\n",
    "index2word = ['_'] + [UNK] + [ x[0] for x in vocab ]\n",
    "word2index = dict([(w,i) for i,w in enumerate(index2word)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unk(qtokenized, atokenized, w2idx):\n",
    "    data_len = len(qtokenized)\n",
    "\n",
    "    filtered_q, filtered_a = [], []\n",
    "\n",
    "    for qline, aline in zip(qtokenized, atokenized):\n",
    "        unk_count_q = len([ w for w in qline if w not in w2idx ])\n",
    "        unk_count_a = len([ w for w in aline if w not in w2idx ])\n",
    "        if unk_count_a <= 2:\n",
    "            if unk_count_q > 0:\n",
    "                if unk_count_q/len(qline) > 0.2:\n",
    "                    pass\n",
    "            filtered_q.append(qline)\n",
    "            filtered_a.append(aline)\n",
    "\n",
    "    return filtered_q, filtered_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter unknowns\n",
    "qtokenized, atokenized = filter_unk(question_tokens, answer_tokens, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can',\n",
       " 'we',\n",
       " 'make',\n",
       " 'this',\n",
       " 'quick',\n",
       " 'roxanne',\n",
       " 'korrine',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'barrett',\n",
       " 'are',\n",
       " 'having',\n",
       " 'an',\n",
       " 'incredibly',\n",
       " 'horrendous',\n",
       " 'public',\n",
       " 'break',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'quad',\n",
       " 'again']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'wed',\n",
       " 'start',\n",
       " 'with',\n",
       " 'pronunciation',\n",
       " 'if',\n",
       " 'thats',\n",
       " 'okay',\n",
       " 'with',\n",
       " 'you']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = len(question_tokens)\n",
    "# numpy arrays to store indices\n",
    "idx_q = np.zeros([data_len, 25], dtype=np.int32) \n",
    "idx_a = np.zeros([data_len, 25], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98706, 25)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98706"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq, lookup, maxlen):\n",
    "    indices = []\n",
    "    for word in seq:\n",
    "        if word in lookup:\n",
    "            indices.append(lookup[word])\n",
    "        else:\n",
    "            indices.append(lookup[UNK])\n",
    "    return indices + [0]*(maxlen - len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_len):\n",
    "    q_indices = pad_seq(question_tokens[i], word2index, 25)\n",
    "    a_indices = pad_seq(answer_tokens[i], word2index, 25)\n",
    "    idx_q[i] = np.array(q_indices)\n",
    "    idx_a[i] = np.array(a_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  52,   22,  114,   17,  899,    1,    1,   11, 4069, 7579,   28,\n",
       "        410,   81, 3704,    1, 1257,  501,   55,   29,    4,    1,  183,\n",
       "          0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43,   3, 140, 605, 331,  34,   1,  46,  49, 106,  34,   2,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('idx_q.npy', idx_q)\n",
    "np.save('idx_a.npy', idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "        'w2idx' : word2index,\n",
    "        'idx2w' : index2word,\n",
    "        'freq_dist' : freq_dist\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(PATH=''):\n",
    "    # read data control dictionaries\n",
    "    with open(PATH + 'metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    # read numpy arrays\n",
    "    idx_q = np.load(PATH + 'idx_q.npy')\n",
    "    idx_a = np.load(PATH + 'idx_a.npy')\n",
    "    return metadata, idx_q, idx_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, ratio = [0.7, 0.15, 0.15] ):\n",
    "    # number of examples\n",
    "    data_len = len(x)\n",
    "    lens = [ int(data_len*item) for item in ratio ]\n",
    "\n",
    "    trainX, trainY = x[:lens[0]], y[:lens[0]]\n",
    "    testX, testY = x[lens[0]:lens[0]+lens[1]], y[lens[0]:lens[0]+lens[1]]\n",
    "    validX, validY = x[-lens[-1]:], y[-lens[-1]:]\n",
    "\n",
    "    return (trainX,trainY), (testX,testY), (validX,validY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY), (validX, validY) = split_dataset(idx_q, idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xseq_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e278144d169f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m self.enc_ip = [ tf.placeholder(shape=[None,],\n\u001b[1;32m      3\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 name='ei_{}'.format(t)) for t in range(xseq_len) ]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m self.labels = [ tf.placeholder(shape=[None,],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xseq_len' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "self.enc_ip = [ tf.placeholder(shape=[None,],\n",
    "                dtype=tf.int64,\n",
    "                name='ei_{}'.format(t)) for t in range(xseq_len) ]\n",
    "\n",
    "self.labels = [ tf.placeholder(shape=[None,],\n",
    "                dtype=tf.int64,\n",
    "                name='ei_{}'.format(t)) for t in range(yseq_len) ]\n",
    "\n",
    "self.dec_ip = [ tf.zeros_liek(self.enc_ip[0], dtype=tf.int64, name='GO')] + self.labels[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
