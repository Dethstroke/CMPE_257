{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import nltk\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import configuration as config\n",
    "from os import path\n",
    "import seq2seq_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
       " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
       " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n",
       " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n",
       " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_ids = {}\n",
    "for line in lines:\n",
    "    line_lst = line.split(' +++$+++ ')\n",
    "    if len(line_lst) == 5:\n",
    "        line_ids[line_lst[0]] = line_lst[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\"]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = []\n",
    "for line in conv:\n",
    "    line_lst = line.split(' +++$+++ ')\n",
    "    line = line_lst[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
    "    convs.append(line.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate question and answers \n",
    "questions = []\n",
    "answers = []\n",
    "for conv in convs:\n",
    "    if len(conv) %2 != 0:\n",
    "        conv = conv[:-1]    \n",
    "    for i in range(len(conv)):\n",
    "        if i%2 == 0:\n",
    "            questions.append(line_ids[conv[i]])\n",
    "        else:\n",
    "            answers.append(line_ids[conv[i]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to lowercase\n",
    "questions = [ line.lower() for line in questions ]\n",
    "answers = [ line.lower() for line in answers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can we make this quick?  roxanne korrine and andrew barrett are having an incredibly horrendous public break- up on the quad.  again.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"well, i thought we'd start with pronunciation, if that's okay with you.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters \n",
    "EN_WHITELIST = '0123456789abcdefghijklmnopqrstuvwxyz ' # space is included in whitelist\n",
    "EN_BLACKLIST = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\''\n",
    "def filter_line(line, whitelist):\n",
    "    return ''.join([ ch for ch in line if ch in whitelist ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [ filter_line(line, EN_WHITELIST) for line in questions ]\n",
    "answers = [ filter_line(line, EN_WHITELIST) for line in answers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can we make this quick  roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad  again'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well i thought wed start with pronunciation if thats okay with you'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(qseq, aseq):\n",
    "    filtered_q, filtered_a = [], []\n",
    "    raw_data_len = len(qseq)\n",
    "    for i in range(raw_data_len):\n",
    "        qlen, alen = len(qseq[i].split(' ')), len(aseq[i].split(' '))\n",
    "        if qlen >= 2 and qlen <= 25:\n",
    "            if alen >= 2 and alen <= 25:\n",
    "                filtered_q.append(qseq[i])\n",
    "                filtered_a.append(aseq[i])\n",
    "\n",
    "    return filtered_q, filtered_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = filter_data(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "question_tokens = [ [w.strip() for w in wordlist.split(' ') if w] for wordlist in questions ]\n",
    "answer_tokens   = [ [w.strip() for w in wordlist.split(' ') if w] for wordlist in answers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can',\n",
       " 'we',\n",
       " 'make',\n",
       " 'this',\n",
       " 'quick',\n",
       " 'roxanne',\n",
       " 'korrine',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'barrett',\n",
       " 'are',\n",
       " 'having',\n",
       " 'an',\n",
       " 'incredibly',\n",
       " 'horrendous',\n",
       " 'public',\n",
       " 'break',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'quad',\n",
       " 'again']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'wed',\n",
       " 'start',\n",
       " 'with',\n",
       " 'pronunciation',\n",
       " 'if',\n",
       " 'thats',\n",
       " 'okay',\n",
       " 'with',\n",
       " 'you']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization: Words to index and index to words\n",
    "UNK = 'unk'\n",
    "freq_dist = nltk.FreqDist(itertools.chain(*(question_tokens + answer_tokens)))\n",
    "vocab = freq_dist.most_common(8000)\n",
    "index2word = ['_'] + [UNK] + [ x[0] for x in vocab ]\n",
    "word2index = dict([(w,i) for i,w in enumerate(index2word)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unk(qtokenized, atokenized, w2idx):\n",
    "    data_len = len(qtokenized)\n",
    "\n",
    "    filtered_q, filtered_a = [], []\n",
    "\n",
    "    for qline, aline in zip(qtokenized, atokenized):\n",
    "        unk_count_q = len([ w for w in qline if w not in w2idx ])\n",
    "        unk_count_a = len([ w for w in aline if w not in w2idx ])\n",
    "        if unk_count_a <= 2:\n",
    "            if unk_count_q > 0:\n",
    "                if unk_count_q/len(qline) > 0.2:\n",
    "                    pass\n",
    "            filtered_q.append(qline)\n",
    "            filtered_a.append(aline)\n",
    "\n",
    "    return filtered_q, filtered_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter unknowns\n",
    "qtokenized, atokenized = filter_unk(question_tokens, answer_tokens, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can',\n",
       " 'we',\n",
       " 'make',\n",
       " 'this',\n",
       " 'quick',\n",
       " 'roxanne',\n",
       " 'korrine',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'barrett',\n",
       " 'are',\n",
       " 'having',\n",
       " 'an',\n",
       " 'incredibly',\n",
       " 'horrendous',\n",
       " 'public',\n",
       " 'break',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'quad',\n",
       " 'again']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'wed',\n",
       " 'start',\n",
       " 'with',\n",
       " 'pronunciation',\n",
       " 'if',\n",
       " 'thats',\n",
       " 'okay',\n",
       " 'with',\n",
       " 'you']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = len(question_tokens)\n",
    "# numpy arrays to store indices\n",
    "idx_q = np.zeros([data_len, 25], dtype=np.int32) \n",
    "idx_a = np.zeros([data_len, 25], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98706, 25)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98706"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq, lookup, maxlen):\n",
    "    indices = []\n",
    "    for word in seq:\n",
    "        if word in lookup:\n",
    "            indices.append(lookup[word])\n",
    "        else:\n",
    "            indices.append(lookup[UNK])\n",
    "    return indices + [0]*(maxlen - len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_len):\n",
    "    q_indices = pad_seq(question_tokens[i], word2index, 25)\n",
    "    a_indices = pad_seq(answer_tokens[i], word2index, 25)\n",
    "    idx_q[i] = np.array(q_indices)\n",
    "    idx_a[i] = np.array(a_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  52,   22,  114,   17,  899,    1,    1,   11, 4114, 7938,   28,\n",
       "        411,   81, 3744,    1, 1256,  501,   55,   29,    4,    1,  183,\n",
       "          0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43,   3, 140, 608, 331,  34,   1,  46,  49, 106,  34,   2,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('idx_q.npy', idx_q)\n",
    "np.save('idx_a.npy', idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "        'w2idx' : word2index,\n",
    "        'idx2w' : index2word,\n",
    "        'freq_dist' : freq_dist\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(PATH=''):\n",
    "    # read data control dictionaries\n",
    "    with open(PATH + 'metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    # read numpy arrays\n",
    "    idx_q = np.load(PATH + 'idx_q.npy')\n",
    "    idx_a = np.load(PATH + 'idx_a.npy')\n",
    "    return metadata, idx_q, idx_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, ratio = [0.7, 0.15, 0.15] ):\n",
    "    # number of examples\n",
    "    data_len = len(x)\n",
    "    lens = [ int(data_len*item) for item in ratio ]\n",
    "\n",
    "    trainX, trainY = x[:lens[0]], y[:lens[0]]\n",
    "    testX, testY = x[lens[0]:lens[0]+lens[1]], y[lens[0]:lens[0]+lens[1]]\n",
    "    validX, validY = x[-lens[-1]:], y[-lens[-1]:]\n",
    "\n",
    "    return (trainX,trainY), (testX,testY), (validX,validY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY), (validX, validY) = split_dataset(idx_q, idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52  22 114 ...   0   0   0]\n",
      " [ 24   4   1 ...   0   0   0]\n",
      " [ 36 573  12 ...   0   0   0]\n",
      " ...\n",
      " [ 22 162 218 ...   0   0   0]\n",
      " [ 26 218  13 ...   0   0   0]\n",
      " [427  12   8 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "xseq_length = trainX.shape[-1]\n",
    "yseq_length = trainY.shape[-1]\n",
    "batch_size = config.batch_size\n",
    "xvocab_size = len(metadata['idx2w'])\n",
    "yvocab_size = xvocab_size\n",
    "checkpoint_path = path.join(config.path_outputs, 'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/CMPE_257/RNN/outputs/checkpoint\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seq2seq_wrapper.Seq2Seq(xseq_len=xseq_length,\n",
    "                                yseq_len=yseq_length,\n",
    "                                xvocab_size=xvocab_size,\n",
    "                                yvocab_size=yvocab_size,\n",
    "                                emb_dim=config.embedding_dim,\n",
    "                                num_layers=3,\n",
    "                                ckpt_path=checkpoint_path)\n",
    "\n",
    "val_batch_gen = data_utils.generate_random_batch(x_valid, y_valid, config.batch_size)\n",
    "train_batch_gen = data_utils.generate_random_batch(x_train, y_train, config.batch_size)\n",
    "\n",
    "sess = model.restore_last_session()\n",
    "sess = model.train(train_batch_gen, val_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
